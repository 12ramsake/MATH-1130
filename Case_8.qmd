# Hypothesis testing I

One of the key problems in data science is assessing whether a pattern you notice is :

1. a pattern inherent in the overall population from which the observations are drawn

OR

2. a spurious pattern specific to the sample of observations you have.

In this case, you learnt a fundamental tool to approach this problem called **statistical hypothesis testing**. 
You should know how to conduct a hypothesis test, analyze its outcome, and identify its shortcomings.

## Preliminary modules


```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
from statsmodels.formula.api import ols
import statsmodels
from scipy import stats 
from pingouin import pairwise_tests #this is for performing the pairwise tests
from pingouin import pairwise_ttests #this is for performing the pairwise tests
```

## Hypothesis testing overview



Hypothesis help you rule out *sampling variation* as an explanation for an observed pattern in a data set. It helps us lift a pattern from a sample to a population. The idea is this - every data set we have seen in this course is comprised of a small subset of a population we are interested in learning about. 
That small subset is called a sample. 
For instance, in the previous case, we were interested in the population of trips taken on the rentable bikes. 
We had access to a small subset of the trips taken - this is the sample. 
Now, there is a small problem with the results of any data analysis. The subset of observations or sample that we have access to is random. 
We could have easily drawn a different subset and a different subset will give different output in data analysis - that is - different plots and summary statistics. 
For instance, the average length of a bike trip could be 45 minutes in one subset and 30 minutes in another. 
The true average bike trip length for the population could be anything - say 39. 
The purpose of hypothesis testing is to rule out the situation where the sample may not resemble the population. 
In other words, it is useful to say that the conclusions made in our data analysis are likely to reflect that of the population, and are not due to drawing a bad sample. 


In this course, we will mainly focus on saying something about the mean of potentially several populations. 
In general, the hypothesis testing procedure concerns two hypotheses - the null and alternative hypothesis. 
These contain mutually exclusive statements about a population. 

For example: 
$$H_0: \text{The population trip length is } 40\ vs.\ H_a: \text{The population trip length is not } 40.$$

$H_0$ is called the null hypothesis. 
The null hypothesis often corresponds to the situation of "no effect" - but not always. 


In opposition to the null hypothesis, we define an alternative hypothesis (often indicated with $H_1$ or $H_a$) to challenge the null hypothesis. 
In general, this is the hypothesis of there existing some pattern or effect in the data. 

For instance, we may suspect that the average trip length is 40, and we may be concerned about whether our data shows that the trip length is longer than this. This may be of concern for computing bike maintenance costs. In that case, we would define $H_a: \text{The population trip length is greater than } 40.$ 


The next step in a hypothesis test is to compute a **p-value** using our sample. The p-value measures the evidence against the null hypothesis. It is a number between 0 and 1.
The closer to 0 the p-value is, the more evidence there is against the null hypothesis. 
The p-value can be interpreted as follows: The p-value is the probability that, assuming the null hypothesis is true, we drew a sample that differs from the null hypothesis at least as much as the one at hand. 


Let's unpack this statement using our example. First, before computing our p-value we assume that the null hypothesis is true. In our example, we would assume that the mean population trip length is 40 minutes. Then, if the mean population trip length is 40 minutes we can measure how far the sample mean is from 40. 
Say that our sample mean is 45, and so then we would have observed a sample whose mean is 5 minutes higher than that of the assumed population mean. 
The p-value is then the probability that we saw a sample whose sample mean is at least 5 minutes away from 40. 
You will learn in a later course how to compute such a probability. 
Intuitively, the higher the distance of the sample mean from 40, the lower the p-value. 
Therefore, if we observe a sample mean far from 40, the p-value will be very close to 0. 
We can interpret the p-value as the probability, assuming the mean population trip length is 40, that we drew a sample whose mean differs from 40 at least as much as the one at hand. 

:::{.callout-caution}
The $p$-value DOESN'T mean that the probability of $H_a$ is 1-($p$ - value).
:::

In general, p-values close to 0, as in <0.1 or <0.05 present evidence against the null hypothesis. 
This threshold can depend on the application. 
 

When doing a formal hypothesis tests, there are two possible outcomes for a test: 
- (1) We conclude $H_0$ is false, and say we **reject $H_0$**. In this case we will conclude that there is statistical evidence for the alternative $H_a$. 
- Or (2) we **fail to reject $H_0$**. In this case, we conclude that there is not enough statistical evidence to say that $H_0$ is false. 

:::{.callout-caution}
Notice that in the second case we cannot say that the original hypothesis is true - it might be that we just don't have enough data to rule it out. 
:::

In a formal hypothesis test, we define a threshold $\alpha$, where if the $p$-value falls below this threshold, then we reject the null hypothesis. In general, less formal cases, one may just compute the p-value and use it to inform decision making, along with other factors. 


To summarize: 

1. A hypothesis test is used to confirm that a pattern is a feature of the population, and is not due to sampling variation. 
2. To conduct a hypothesis test, we define a null and alternative hypothesis. 
3. After defining the hypohtheses, we then compute the evidence against the null hypothesis, given by the $p$-value. 
4. If the $p$-value is small, we reject the null hypothesis and conclude the alternative. Otherwise, we fail to reject the null hypothesis. 
5. **You should always interpret the $p$-value and state your conclusion as the final step in the hypothesis test.** 

To elaborate on point 5. - the point of any statistical analysis is not to run the correct code, but to properly choose the analysis procedure and interpret the results appropriately. 

:::{.callout-warning}
A hypothesis test cannot tell you which scenario is certainly true - we would have to have access to the whole population to know that. It can tell us that things hold with very high certainty, which is generally enough for most situations.
:::


The hypothesis tests introduced in Case 8 concern only testing for the mean of one or more populations. 
We cover each of those in turn. 


## Testing for the mean in a single population

We first cover how to perform a hypothesis test concerning the mean value of a single population. 
Define the population mean of a single population to be $\mu$. 
The null hypothesis in this case is in the form of $H_0\colon \mu=\mu_0$. 
For instance, above, $\mu_0=40$. 

We have three different ways to define an alternative hypothesis:

1. $H_a: \mu \neq \mu_0$ (two-sided test)

2. $H_a: \mu > \mu_0$ (one-sided test)

3. $H_a: \mu < \mu_0$ (one-sided test)

The syntax for perfomring the test is given as follows: 

```python
stats.ttest_1samp(Series you want to test, popmean= mu_0, alternative= specify which of (1-3) here)
```
The $p$-value is listed in the output, and can be interpreted as instructed above. 

## Testing for a difference in mean for two populations

We now cover how to perform a hypothesis test concerning the difference in the mean values between two populations. 
We would like to test whether two populations have different population means. 
That is, whether the difference between the population mean of  group 1 ($\mu_1$) is different from the population mean of group 2 ($\mu_2$). 
The hypotheses look like:
$$ H_0: \mu_1=\mu_2$$
$$H_a: \mu_1 \neq \mu_2$$

The syntax for performing this test is given as follows: 

```python
stats.ttest_ind(data for group 1 , data for group 2, equal_var=False)
```
The $p$-value is listed in the output, and can be interpreted as instructed above. 

## Testing for a difference in mean for several populations

Lastly, if we would like to perform a hypothesis test for whether or not all the population means are the same when considering $k>2$ populations, we can do the following. 

First, the hypotheses are given by

$$H_0: \mu_1=\mu_2\ldots\mu_3=\mu_k,$$
vs.
$$H_a : \mathrm{At \,least\, one\, of\, the\, means\,} \mu_j \mathrm{\,is \,different\, from\, the \,others}.$$

To test this hypothesis we need an extension of the capabilities of the $t$ - test (which can test only two groups at the same time). This test is called **Analysis of Variance (ANOVA)**. 

The syntax is given as follows: 

```python
# This is code you can fill in to perform this test
mod = ols('quantity of interest ~ grouping variable', data= YOUR_DATAFRAME).fit()  
sm.stats.anova_lm(mod, typ=2)
```
The $p$-value is listed in the output, and can be interpreted as instructed above. 


## Errors in hypothesis testing

There are two ways that a test can lead us to an incorrect decision:

1. When $H_0$ is true and we reject it. This is called **Type 1 Error**. It corresponds to obtaining a **false positive**.
2. When $H_0$ is false and we do not reject it. This is called **Type 2 Error**. It corresponds to having a **false negative**.

<table>
<tr>
<td></td><td><b>$H_0$ is true </b></td><td><b> $H_0$ is False</b></td>
</tr>
<tr>
<td><b>Reject $H_0$</b></td><td>Type I error</td><td>Correct Decision (True Positive)</td>
</tr>
<tr>
<td><b>Fail to Reject $H_0$ </b></td><td>Correct Decision (True negative) </td><td>Type II error</td>
</tr>
</table>

In general, a Type I error is thought to be more serious and so it is standard practice to control the probability of making a Type I error. In a formal hypothesis test, when the null hypothesis is true, the probability of making a Type I error is the threshold $\alpha$, also known as the significance level, that we introduced above. Often, we choose our significance level $\alpha$ to be small, e.g., $1\%,5\%,10\%$. Lowering the $\alpha$ value (say to $1\%$) will decrease the probability of making a false positive conclusion, when the null hypothesis is true. Of course, because we control $\alpha$, we cannot control the Type II error we make. Note that lowering $\alpha$ is not without consequence, as, if the alternative hypothesis is true, then a lower threshold increases the probability of a Type II error. 

In summary, it is important to be aware of the two types of error and evaluate the gravity of what making each error would mean for your context. 
In particular, you should evaluate the consequences of making a Type I error and choose your the threshold $\alpha$ accordingly. 
Lastly, you should know that there is a trade-of between Type I error and Type II error in a given hypothesis test. 





## Misc. Python functions


1. `plt.subplot(rows, cols, curr_plot)` - use this function to position multiple plots in a single figure. For example, `plt.subplot(2, 3, 4)` creates a grid with 2 rows and 3 columns and activates the 4th subplot.

2. `sns.countplot` - creates a barplot.

3. `enumerate` Use this function to get both the index and the value from an iterable in a loop.
Example:
```{python}
fruits = ['apple', 'banana', 'cherry']
for index, fruit in enumerate(fruits, start=1):
    print(f"{index}: {fruit}")
```


4. `plt.xticks(rotation = 90)` used to rotate the $x$-axis labels. 